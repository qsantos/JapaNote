from collections import deque
from typing import Iterator, Optional, Deque

from .kanji import load_kanjidic

kanjidic = None


def hiragana_to_katakana(c: str) -> str:
    return chr(ord(c) - 0x3041 + 0x30a1)


assert hiragana_to_katakana('ã‚') == 'ã‚¢'
assert hiragana_to_katakana('ã£') == 'ãƒƒ'


def lengthen_vowel(s: str) -> Optional[str]:
    last_kana = s[-1]
    if last_kana in 'ã‹ã•ãŸãªã¯ã¾ã‚„ã‚‰ã‚ãŒã–ã ã°ã±ã‹ã‚šã‚‰ã‚šã‚ƒ': return s + 'ã‚'
    if last_kana in 'ãã—ã¡ã«ã²ã¿ğ›€†ã‚Šã‚ãã˜ã¢ã³ã´ãã‚šã‚Šã‚š': return s + 'ã„'
    if last_kana in 'ãã™ã¤ã¬ãµã‚€ã‚†ã‚‹ğ›„Ÿããšã¥ã¶ã·ãã‚šã‚‹ã‚šã‚…': return s + 'ã†'
    if last_kana in 'ã‘ã›ã¦ã­ã¸ã‚ğ›€ã‚Œã‚‘ã’ãœã§ã¹ãºã‘ã‚šã‚Œã‚š': return s + 'ãˆ'
    if last_kana in 'ã“ãã¨ã®ã»ã‚‚ã‚ˆã‚ã‚’ã”ãã©ã¼ã½ã“ã‚šã‚ã‚šã‚‡': return s + 'ãŠ'
    return None


def furigana_from_kanji_kana(kanji: str, kana: str) -> str:
    matches = list(match_from_kanji_kana(kanji, kana))
    return furigana_from_match(matches[0])


def match_from_kanji_kana(kanji: str, kana: str) -> Iterator[list[tuple[str, str]]]:
    """Match kanji against kana

    Return a generator that yields all possible matches of kanji with the kana
    based on their known readings. For instance, for 'ç‰›è‚‰' and 'ãã‚…ã†ã«ã',
    it yields the single match [('ç‰›', 'ãã‚…ã†'), ('è‚‰', 'ã«ã')].
    """
    global kanjidic
    if kanjidic is None:
        kanjidic = load_kanjidic()

    default = [(kanji, kana)]
    q: Deque[tuple[list[tuple[str, str]], str, str]] = deque([([], kanji, kana)])
    while q:
        match_prefix, kanji, kana = q.popleft()
        # skip not-kanji
        if not kanji and not kana:
            yield match_prefix
        if not kanji or not kana:
            continue
        # look up kanji readings
        c = kanji[0]
        if c == 'ã€…' and match_prefix:
            readings = [match_prefix[-1][1]]  # TODO: dakuten
        else:
            try:
                kanjiinfo = kanjidic[c]
            except KeyError:
                readings = [c]
            else:
                readings = kanjiinfo.readings
        # add lengthened readings (lower priority)
        lengthened_readings = []
        for reading in readings:
            lengthened = lengthen_vowel(reading)
            if lengthened is not None:
                lengthened_readings.append(lengthened)
        readings.extend(lengthened_readings)
        # remove duplicates while maintaining order
        readings = list(dict.fromkeys(readings))
        # recurse
        for reading in readings:
            if hiragana_to_katakana(kana[0]) == reading or kana.startswith(reading):
                new_prefixes = match_prefix + [(c, reading)]
                new_kanji = kanji[1:]
                new_kana = kana[len(reading):]
                new_element = (new_prefixes, new_kanji, new_kana)
                q.append(new_element)
    yield default


def furigana_from_match(match: list[tuple[str, str]]) -> str:
    """Transform a kanji-kana match into Anki-compatible furigana

    For instance, for [('ç‰›', 'ãã‚…ã†'), ('è‚‰', 'ã«ã')], it returns
    'ç‰›[ãã‚…ã†]è‚‰[ã«ã]'.
    """
    def _() -> Iterator[str]:
        last_was_kana = False
        for kanji, kana in match:
            if kanji == kana:
                yield kana
            else:
                if last_was_kana:
                    yield ' '
                yield f'{kanji}[{kana}]'
            last_was_kana = kanji == kana
    return ''.join(_())


def _test(kanji: str, kana: str, expected: str):
    """Test furigana_from_kanji_kana() against expected result"""
    furigana = furigana_from_kanji_kana(kanji, kana)
    if furigana != expected:
        print(f'ERROR: furigana_from_kanji_kana(repr({kanji}), repr({kana}) returns the wrong result')
        print(f'Output:   {repr(furigana)}')
        print(f'Expected: {repr(expected)}')
        raise AssertionError


_test('ç§', 'ã‚ãŸã—', 'ç§[ã‚ãŸã—]')
_test('ç‰›è‚‰', 'ãã‚…ã†ã«ã', 'ç‰›[ãã‚…ã†]è‚‰[ã«ã]')
_test('ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å', 'ã„ã¡ã«ã•ã‚“ã—ã”ã‚ããªãªã¯ã¡ãã‚…ã†ã˜ã‚…ã†', 'ä¸€[ã„ã¡]äºŒ[ã«]ä¸‰[ã•ã‚“]å››[ã—]äº”[ã”]å…­[ã‚ã]ä¸ƒ[ãªãª]å…«[ã¯ã¡]ä¹[ãã‚…ã†]å[ã˜ã‚…ã†]')
_test('ç­‰ã€…', 'ãªã©ãªã©', 'ç­‰[ãªã©]ã€…[ãªã©]')
_test('æ—¥å¸°ã‚Š', 'ã²ãŒãˆã‚Š', 'æ—¥[ã²]å¸°[ãŒãˆ]ã‚Š')
_test('åˆ¤å®˜', 'ã¯ã‚“ãŒã‚“', 'åˆ¤[ã¯ã‚“]å®˜[ãŒã‚“]')
_test('è´”å±“', 'ã²ã„ã', 'è´”[ã²ã„]å±“[ã]')
_test('åˆ¤å®˜è´”å±“', 'ã¯ã‚“ãŒã‚“ã³ã„ã', 'åˆ¤[ã¯ã‚“]å®˜[ãŒã‚“]è´”[ã³ã„]å±“[ã]')
_test('ãƒ¡ãƒƒã‚¿åˆºã—', 'ã‚ã£ãŸã–ã—', 'ãƒ¡ãƒƒã‚¿ åˆº[ã–]ã—')
_test('æ–‡å­—', 'ã‚‚ã˜', 'æ–‡[ã‚‚]å­—[ã˜]')
_test('æ¥”å½¢æ–‡å­—', 'ãã•ã³ãŒãŸã‚‚ã˜', 'æ¥”[ãã•ã³]å½¢[ãŒãŸ]æ–‡[ã‚‚]å­—[ã˜]')
